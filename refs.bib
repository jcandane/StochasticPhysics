@article{Rahn1972,
  title = {Neutron Resonance Spectroscopy. X. $^{232}\mathrm{Th}$ and $^{238}\mathrm{U}$},
  author = {Rahn, F. and Camarda, H. S. and Hacken, G. and Havens, W. W. and Liou, H. I. and Rainwater, J. and Slagowitz, M. and Wynchank, S.},
  journal = {\href{https://link.aps.org/doi/10.1103/PhysRevC.6.1854}{Phys. Rev. C}},
  volume = {6},
  issue = {5},
  pages = {1854--1869},
  numpages = {0},
  year = {1972},
  month = {Nov},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevC.6.1854},
  url = {https://link.aps.org/doi/10.1103/PhysRevC.6.1854}
}


@article{Wishart1928,
  title={The Generalised Product Moment Distribution in samples from a normal multivariate Population},
  author={Wishart, John},
  journal={Biometrika},
  pages={32--52},
  year={1928},
  publisher={JSTOR}
}


@article{Wigner1955,
  title={Characteristic vectors of bordered matrices with infinite dimensions},
  author={Wigner, Eugene P},
  journal={\href{https://www.jstor.org/stable/1970079}{Annals of Mathematics}},
  pages={548--564},
  year={1955},
  publisher={Mathematics Department, Princeton University}
}

@article{Wigner1957,
  title={Characteristic vectors of bordered matrices with infinite dimensions II},
  author={Wigner, Eugene P},
  journal={\href{https://www.jstor.org/stable/1969956}{Annals of Mathematics}},
  pages={203--207},
  year={1957},
  publisher={Mathematics Department, Princeton University}
}

@book{DiFrancesco2011,
  title={The Oxford handbook of Random Matrix Theory},
  author={Akemann, Gernot and Baik, Jinho and Di Francesco, Philippe},
  year={2011},
  publisher={Oxford University Press}
}


@book{Jaynes,
  title={Probability Theory: The Logic of Science},
  author={Jaynes, Edwin T},
  year={2003},
  publisher={Cambridge University Press}
}



@article{DiFrancesco1993,
  title={2D Gravity and Random Matrices},
  author={Di Francesco, Philippe and Ginsparg, Paul and Zinn-Justin, Jean},
  journal={\href{https://www.sciencedirect.com/science/article/abs/pii/037015739400084G}{Physics Reports}},
  volume={254},
  number={1-2},
  pages={1--133},
  year={1995},
  publisher={Elsevier},
  note={\href{https://arxiv.org/abs/hep-th/9306153}{arXiv:hep-th/9306153}},
}





@book{Mehta2004,
  title={Random Matrices},
  author={Mehta, Madan Lal},
  year={2004},
  publisher={Elsevier}
}


@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}


@article{Tensorly,
  title={Tensorly: Tensor learning in python},
  author={\textsc{Tensorly} and Kossaifi, Jean and Panagakis, Yannis and Anandkumar, Anima and Pantic, Maja},
  journal={\href{https://arxiv.org/pdf/1610.09555.pdf}{arXiv:1610.09555}},
  year={2016}
}



@article{Paszke2019,
  title={Pytorch: An Imperative Style, High-Performance Deep Learning Library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@software{Jax2018,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
}



@misc{tensorflow2015,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}




@article{Pfeifer2014,
  title={NCON: A Tensor Network Contractor for MATLAB},
  author={Pfeifer, Robert NC and Evenbly, Glen and Singh, Sukhwinder and Vidal, Guifre},
  note={\href{https://arxiv.org/pdf/1402.0939.pdf}{	arXiv:1402.0939}},
  year={2014}
}

@article{2020SciPy,
  author  = {SciPy and Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}


@article{         numpy2020,
 title         = {Array programming with {NumPy}},
 author        = {NumPy and Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}



@book{Baxter2008,
  title={Exactly Solved Models in Statistical Mechanics},
  author={Baxter, Rodney J},
  year={2008},
  publisher={Dover Publications}
}


@article{candanedo2023b,
  title={Graphs to Networks},
  author={Candanedo, Julio J.},
  year={2023},
  publisher={arXiv}}
  %note={link} %%\href{https://arxiv.org/pdf/2303.10784.pdf}{	arXiv:2303.10784}}
%}



@article{candanedo2023a,
  title={Sparse Partial-Tracing},
  author={Candanedo, Julio J.},
  year={2023},
  publisher={arXiv},
  note={\href{https://arxiv.org/pdf/2303.10784.pdf}{	arXiv:2303.10784}}
}




@book{williams2006gaussian,
  title={Gaussian Processes for Machine Learning},
  author={Williams, Christopher KI and Rasmussen, Carl Edward},
  volume={2},
  number={3},
  year={2006},
  publisher={MIT press}
}




@article{Verstraete2008,
  title={Matrix Product States, Projected Entangled Pair
States, and variational renormalization group
methods for quantum spin systems},
  author={Verstraete, F. and Cirac, J.I. and V. Murg},
  year={2008},
  publisher={arXiv},
  note={\href{https://arxiv.org/pdf/0907.2796.pdf}{	arXiv:0907.2796}}
}

@article{pirvu2010,
  title={Matrix Product Operator Representations},
  author={Pirvu, Bogdan and Murg, Valentin and Cirac, J Ignacio and Verstraete, Frank},
  journal={New Journal of Physics},
  volume={12},
  number={2},
  pages={025012},
  year={2010},
  publisher={IOP Publishing},
  note={\href{https://arxiv.org/pdf/0804.3976.pdf}{	arXiv:0804.3976}}
}

@article{davidson1975,
  title={The iterative calculation of a few of the lowest eigenvalues and corresponding eigenvectors of large real-symmetric matrices},
  author={Davidson, Ernest R.},
  journal={J. Comput. Phys},
  volume={17},
  pages={87--94},
  year={1975}
}



@article{davidson1993,
  title={Monster Matrices: their Eigenvalues and Eigenvectors},
  author={Davidson, Ernest R and Thompson, William J},
  journal={Computers in Physics},
  volume={7},
  number={5},
  pages={519--522},
  year={1993},
  publisher={American Institute of Physics}
}

@book{Arnold,
  title={Mathematical Methods of Classical Mechanics},
  author={Arnol'd, Vladimir Igorevich},
  volume={60},
  year={1989},
  publisher={Springer Science \& Business Media}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


@article{Teixeira2022,
  title={Benchmarking autonomous scattering experiments illustrated on TAS},
  author={Teixeira Parente, Mario and Schneidewind, Astrid and Brandl, Georg and Franz, Christian and Noack, Marcus and Boehm, Martin and Ganeva, Marina},
  journal={Frontiers in Materials},
  volume={8},
  pages={772014},
  year={2022},
  publisher={Frontiers}
}


@article{Melton2020,
  title={K-means-driven Gaussian process data collection for angle-resolved photoemission spectroscopy},
  author={Melton, Charles N and Noack, Marcus M and Ohta, Taisuke and Beechem, Thomas E and Robinson, Jeremy and Zhang, Xiaotian and Bostwick, Aaron and Jozwiak, Chris and Koch, Roland J and Zwart, Petrus H and others},
  journal={Machine Learning: Science and Technology},
  volume={1},
  number={4},
  pages={045015},
  year={2020},
  publisher={IOP Publishing}
}



@article{Doerk2023,
  title={Autonomous discovery of emergent morphologies in directed self-assembly of block copolymer blends},
  author={Doerk, Gregory S and Stein, Aaron and Bae, Suwon and Noack, Marcus M and Fukuto, Masafumi and Yager, Kevin G},
  journal={Science advances},
  volume={9},
  number={2},
  pages={eadd3687},
  year={2023},
  publisher={American Association for the Advancement of Science}
} 


@book{Noack2023book,
  title={Methods and Applications of Autonomous Experimentation},
  author={Noack, Marcus and Ushizima, Daniela},
  year={2023},
  publisher={CRC Press}
}

@article{Noack2019,
  title={A kriging-based approach to autonomous experimentation with applications to x-ray scattering},
  author={Noack, Marcus M and Yager, Kevin G and Fukuto, Masafumi and Doerk, Gregory S and Li, Ruipeng and Sethian, James A},
  journal={Sci. Rep.},
  volume={9},
  number={1},
  year={2019},
  publisher={Nature},
  note={\href{https://www.nature.com/articles/s41598-019-48114-3}{s41598-019-48114-3}}
}

@article{Noack2020B,
  title={Autonomous materials discovery driven by Gaussian process regression with inhomogeneous measurement noise and anisotropic kernels},
  author={Noack, Marcus M and Doerk, Gregory S and Li, Ruipeng and Streit, Jason K and Vaia, Richard A and Yager, Kevin G and Fukuto, Masafumi},
  journal={\href{https://www.nature.com/articles/s41598-020-74394-1}{Sci. Rep.}},
  volume={10},
  number={1},
  pages={17663},
  year={2020},
  publisher={Nature},
  note={\href{https://arxiv.org/pdf/2006.02489.pdf}{arXiv:2006.02489}}
}

@article{Noack2021,
  title={Gaussian processes for autonomous data acquisition at large-scale synchrotron and neutron facilities},
  author={Noack, Marcus M and Zwart, Petrus H and Ushizima, Daniela M and Fukuto, Masafumi and Yager, Kevin G and Elbert, Katherine C and Murray, Christopher B and Stein, Aaron and Doerk, Gregory S and Tsai, Esther HR and others},
  journal={Nat. Rev. Phys.},
  volume={3},
  number={10},
  pages={685--697},
  year={2021},
  publisher={Nature}
}

@article{Noack2020A,
  title={Advances in kriging-based autonomous x-ray scattering experiments},
  author={Noack, Marcus M and Doerk, Gregory S and Li, Ruipeng and Fukuto, Masafumi and Yager, Kevin G},
  journal={Sci. Rep.},
  volume={10},
  number={1},
  pages={1325},
  year={2020},
  publisher={Nature}
}


@article{Noack2023_math,
  title={Mathematical Nuances of Gaussian Process-driven Autonomous Experimentation},
  author={Noack, Marcus M and Reyes, Kristofer G},
  journal={\href{https://link.springer.com/article/10.1557/s43577-023-00478-8}{MRS Bulletin}},
  volume={48},
  number={2},
  pages={153--163},
  year={2023},
  publisher={Springer}
}


@article{noack2023unifying,
  title={A Unifying Perspective on Non-Stationary Kernels for Deeper Gaussian Processes},
  author={Noack, Marcus M and Luo, Hengrui and Risser, Mark D},
  journal={arXiv},
  year={2023},
  note={\href{https://arxiv.org/pdf/2309.10068.pdf}{arXiv:2309.10068}}
}


@article{Noack2023sparsity,
  title={Exact Gaussian processes for massive datasets via non-stationary sparsity-discovering kernels},
  author={Noack, Marcus M and Krishnan, Harinarayan and Risser, Mark D and Reyes, Kristofer G},
  journal={\href{https://www.nature.com/articles/s41598-023-30062-8}{Sci. Rep.}},
  volume={13},
  number={1},
  pages={3155},
  year={2023},
  publisher={Nature},
note={\href{https://arxiv.org/pdf/2205.09070.pdf}{arXiv:2205.09070}}
}

%%%%%%%%%%%%%%%%%%%%% GP Libraries

@ARTICLE{GPflow2017,
  author = {Matthews, Alexander G. de G. and {van der Wilk}, Mark and Nickson, Tom and
	Fujii, Keisuke. and {Boukouvalas}, Alexis and {Le{\'o}n-Villagr{\'a}}, Pablo and
	Ghahramani, Zoubin and Hensman, James},
    title = "{{GP}flow: A {G}aussian process library using {T}ensor{F}low}",
  journal = {Journal of Machine Learning Research},
  year    = {2017},
  month = {apr},
  volume  = {18},
  number  = {40},
  pages   = {1-6},
  url     = {http://jmlr.org/papers/v18/16-537.html}
}

@inproceedings{gardner2018gpytorch,
  title={GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration},
  author={Gardner, Jacob R and Pleiss, Geoff and Bindel, David and Weinberger, Kilian Q and Wilson, Andrew Gordon},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}

@Misc{gpy2014,
  author =   {{GPy}},
  title =    {{GPy}: A Gaussian process framework in python},
  howpublished = {\url{http://github.com/SheffieldML/GPy}},
  year = {since 2012}
}

@article{Pinder2022,
  doi = {10.21105/joss.04455},
  url = {https://doi.org/10.21105/joss.04455},
  year = {2022},
  publisher = {The Open Journal},
  volume = {7},
  number = {75},
  pages = {4455},
  author = {Thomas Pinder and Daniel Dodd},
  title = {GPJax: A Gaussian Process Framework in JAX},
  journal = {Journal of Open Source Software}
}

%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{Zhe2019,
  title={Scalable High-Order Gaussian Process Regression},
  author={Zhe, Shandian and Xing, Wei and Kirby, Robert M},
  booktitle={\href{https://users.cs.utah.edu/~kirby/Publications/AISTATS19.pdf}{The 22nd International Conference on Artificial Intelligence and Statistics}},
  pages={2611--2620},
  year={2019},
  organization={PMLR}
}

@article{Liu2020,
  title={When Gaussian process meets big data: A review of scalable GPs},
  author={Liu, Haitao and Ong, Yew-Soon and Shen, Xiaobo and Cai, Jianfei},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={11},
  pages={4405--4423},
  year={2020},
  publisher={IEEE},
  note={\href{https://arxiv.org/pdf/1807.01065.pdf}{arXiv:1807.01065}}
}

@article{Alvarez2012,
  title={Kernels for Vector-Valued Functions: A Review},
  author={Alvarez, Mauricio A and Rosasco, Lorenzo and Lawrence, Neil D and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={4},
  number={3},
  pages={195--266},
  year={2012},
  publisher={Now Publishers, Inc.},
  note={\href{https://arxiv.org/pdf/1106.6251.pdf}{arXiv:1106.6251}}
}


@InProceedings{Kirstein22a,
  title = 	 {Tensor-Train Kernel Learning for Gaussian Processes},
  author =       {Kirstein, Max and Sommer, David and Eigel, Martin},
  booktitle = 	 {Proceedings of the Eleventh Symposium on Conformal and Probabilistic Prediction with Applications},
  pages = 	 {253--272},
  year = 	 {2022},
  editor = 	 {Johansson, Ulf and Boström, Henrik and An Nguyen, Khuong and Luo, Zhiyuan and Carlsson, Lars},
  volume = 	 {179},
  series = 	 { \href{https://proceedings.mlr.press/v179/kirstein22a.html}{Proceedings of Machine Learning Research}},
  month = 	 {24--26 Aug},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v179/kirstein22a/kirstein22a.pdf},
  url = 	 {https://proceedings.mlr.press/v179/kirstein22a.html},
  abstract = 	 {We propose a new kernel learning approach based on efficient low-rank tensor compression for Gaussian process (GP) regression. The central idea is to compose a low-rank function represented in a hierarchical tensor format with a GP covariance function. Compared to similar deep neural network architectures, this approach facilitates to learn significantly more expressive features at lower computational costs as illustrated in the examples. Additionally, over-fitting is avoided with this compositional model by taking advantage of its inherent regularisation properties. Estimates of the generalisation error are compared to five baseline models on three synthetic and six real-world data sets. The experimental results show that the incorporated tensor network enables a highly accurate GP regression with a comparatively low number of trainable parameters. The observed performance is clearly superior (usually by an order of magnitude in mean squared error) to all examined standard models, in particular to deep neural networks with more than 1000 times as many parameters. }
}

 
@article{Maddox2021,
  title={Bayesian Optimization with high-dimensional outputs},
  author={Maddox, Wesley J and Balandat, Maximilian and Wilson, Andrew G and Bakshy, Eytan},
  journal={\href{https://proceedings.neurips.cc/paper/2021/file/a0d3973ad100ad83a64c304bb58677dd-Paper.pdf}{Advances in Neural Information Processing Systems}},
  volume={34},
  pages={19274--19287},
  year={2021},
  note={\href{https://arxiv.org/pdf/2106.12997.pdf}{arXiv:2106.12997v2}}
}


@InProceedings{Astudillo19,
  title = 	 {{B}ayesian Optimization of Composite Functions},
  author =       {Astudillo, Raul and Frazier, Peter},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {354--363},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/astudillo19a/astudillo19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/astudillo19a.html},
  abstract = 	 {We consider optimization of composite objective functions, i.e., of the form $f(x)=g(h(x))$, where $h$ is a black-box derivative-free expensive-to-evaluate function with vector-valued outputs, and $g$ is a cheap-to-evaluate real-valued function. While these problems can be solved with standard Bayesian optimization, we propose a novel approach that exploits the composite structure of the objective function to substantially improve sampling efficiency. Our approach models $h$ using a multi-output Gaussian process and chooses where to sample using the expected improvement evaluated on the implied non-Gaussian posterior on $f$, which we call expected improvement for composite functions (EI-CF). Although EI-CF cannot be computed in closed form, we provide a novel stochastic gradient estimator that allows its efficient maximization. We also show that our approach is asymptotically consistent, i.e., that it recovers a globally optimal solution as sampling effort grows to infinity, generalizing previous convergence results for classical expected improvement. Numerical experiments show that our approach dramatically outperforms standard Bayesian optimization benchmarks, reducing simple regret by several orders of magnitude.}
}


@article{Bridson2007,
  title={Fast Poisson Disk Sampling in Arbitrary Dimensions.},
  author={Bridson, Robert},
  journal={\href{https://dl.acm.org/doi/10.1145/1278780.1278807}{ACM SIGGRAPH sketches}},
  volume={10},
  number={1},
  pages={1},
  year={2007},
  notes={\href{https://www.cs.ubc.ca/~rbridson/docs/bridson-siggraph07-poissondisk.pdf}{pdf}}
}

@article{Halton1964,
  title={Algorithm 247: Radical-Inverse Quasi-Random Point Sequence},
  author={Halton, John H},
  journal={\href{https://dl.acm.org/doi/pdf/10.1145/355588.365104}{Communications of the ACM}},
  volume={7},
  number={12},
  pages={701--702},
  year={1964},
  publisher={ACM New York, NY, USA}
}